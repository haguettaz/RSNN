{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81666b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from scipy.special import lambertw\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cac15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c185a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('scientific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c976003",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'compute_jitter_transition_tensor' from 'rsnn.learning.utils' (/Users/haguettaz/Documents/RSNN/rsnn/learning/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p1/wl8__y5x6jgfhz_d47k5gq9m0000gn/T/ipykernel_15295/2291117883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrsnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiring_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegment_firing_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrsnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mikie\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_box_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_m_ary_prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrsnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_observation_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_jitter_transition_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrsnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_indices_refractory_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_indices_around_firing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrsnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mindices_to_start_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'compute_jitter_transition_tensor' from 'rsnn.learning.utils' (/Users/haguettaz/Documents/RSNN/rsnn/learning/utils.py)"
     ]
    }
   ],
   "source": [
    "from rsnn.spike_sequences.sampling import backward_filtering_forward_sampling\n",
    "from rsnn.spike_sequences.utils import segment_firing_sequences\n",
    "from rsnn.learning.ikie import compute_box_prior, compute_posterior, compute_m_ary_prior\n",
    "from rsnn.learning.utils import compute_observation_tensor, compute_jitter_transition_tensor\n",
    "from rsnn.learning.utils import get_indices_refractory_period, get_indices_around_firing\n",
    "from rsnn.utils.utils import indices_to_start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7378961",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, K, N, Nr, M = 200, 300, 200, 20, 3\n",
    "spike_sequences = backward_filtering_forward_sampling(L, N, Nr)\n",
    "spike_sequences[:, 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d50e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_input = -(1e9) * torch.ones(L, M + 1)  # init with too old spikes\n",
    "for l in range(L):\n",
    "    neuron_spikes = torch.argwhere(spike_sequences[:, l]).squeeze()\n",
    "    num_spikes = neuron_spikes.numel()\n",
    "    if num_spikes == 0:\n",
    "        continue\n",
    "    if num_spikes < M + 1:\n",
    "        org_input[l, -num_spikes:] = neuron_spikes\n",
    "    else:\n",
    "        org_input[l] = neuron_spikes[-(M + 1) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d49bf044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "tmp_input = org_input.clone() - N  # without noise\n",
    "df = pd.DataFrame.from_dict({\"l\": torch.arange(L).repeat_interleave(M + 1), \"s\": tmp_input.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71fdaab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    l             s\n",
       "8   2 -1.000000e+09\n",
       "9   2 -1.000000e+09\n",
       "10  2 -1.000000e+09\n",
       "11  2 -1.000000e+09"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.l == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7ede64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1000e+02, -8.1000e+01, -4.3000e+01, -1.3000e+01],\n",
       "        [-1.1300e+02, -9.0000e+01, -5.4000e+01, -2.4000e+01],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-1.4000e+02, -7.8000e+01, -4.3000e+01, -1.7000e+01],\n",
       "        [-8.9000e+01, -6.7000e+01, -3.8000e+01, -9.0000e+00],\n",
       "        [-9.0000e+01, -5.5000e+01, -2.8000e+01, -7.0000e+00],\n",
       "        [-1.1700e+02, -7.8000e+01, -5.5000e+01, -3.4000e+01],\n",
       "        [-1.1700e+02, -8.4000e+01, -5.1000e+01, -2.3000e+01],\n",
       "        [-9.9000e+01, -6.5000e+01, -4.2000e+01, -1.0000e+00],\n",
       "        [-1.1800e+02, -7.7000e+01, -5.3000e+01, -1.3000e+01],\n",
       "        [-1.0000e+02, -5.8000e+01, -3.7000e+01, -1.4000e+01],\n",
       "        [-8.7000e+01, -6.6000e+01, -3.7000e+01, -1.6000e+01],\n",
       "        [-1.1400e+02, -8.5000e+01, -5.9000e+01, -2.6000e+01],\n",
       "        [-1.6000e+02, -1.2800e+02, -4.8000e+01, -1.9000e+01],\n",
       "        [-1.0700e+02, -7.2000e+01, -4.6000e+01, -1.8000e+01],\n",
       "        [-1.1200e+02, -7.7000e+01, -4.9000e+01, -1.4000e+01],\n",
       "        [-1.1200e+02, -6.8000e+01, -4.6000e+01, -1.2000e+01],\n",
       "        [-9.6000e+01, -7.5000e+01, -5.2000e+01, -2.8000e+01],\n",
       "        [-1.0900e+02, -7.6000e+01, -5.4000e+01, -2.1000e+01],\n",
       "        [-1.0500e+02, -8.3000e+01, -4.4000e+01, -2.1000e+01],\n",
       "        [-8.8000e+01, -6.4000e+01, -3.8000e+01, -1.4000e+01],\n",
       "        [-8.7000e+01, -5.8000e+01, -3.2000e+01, -7.0000e+00],\n",
       "        [-1.0400e+02, -8.1000e+01, -5.7000e+01, -3.3000e+01],\n",
       "        [-1.0600e+02, -7.9000e+01, -5.6000e+01, -1.7000e+01],\n",
       "        [-9.5000e+01, -6.6000e+01, -4.0000e+01, -8.0000e+00],\n",
       "        [-8.6000e+01, -6.2000e+01, -2.9000e+01, -4.0000e+00],\n",
       "        [-9.5000e+01, -6.0000e+01, -3.0000e+01, -1.0000e+00],\n",
       "        [-9.7000e+01, -6.3000e+01, -4.0000e+01, -1.6000e+01],\n",
       "        [-1.3100e+02, -1.0500e+02, -5.0000e+01, -2.0000e+01],\n",
       "        [-1.1500e+02, -8.0000e+01, -4.0000e+01, -1.9000e+01],\n",
       "        [-1.0100e+02, -6.7000e+01, -4.3000e+01, -1.1000e+01],\n",
       "        [-1.3200e+02, -7.9000e+01, -4.8000e+01, -1.6000e+01],\n",
       "        [-8.3000e+01, -5.8000e+01, -3.2000e+01, -1.0000e+01],\n",
       "        [-9.5000e+01, -6.8000e+01, -3.2000e+01, -1.1000e+01],\n",
       "        [-1.0300e+02, -8.2000e+01, -4.9000e+01, -2.4000e+01],\n",
       "        [-1.2800e+02, -9.1000e+01, -6.6000e+01, -1.0000e+01],\n",
       "        [-9.9000e+01, -6.5000e+01, -2.8000e+01, -7.0000e+00],\n",
       "        [-1.1600e+02, -9.2000e+01, -6.5000e+01, -4.1000e+01],\n",
       "        [-9.2000e+01, -6.9000e+01, -4.6000e+01, -1.4000e+01],\n",
       "        [-1.2600e+02, -9.9000e+01, -7.6000e+01, -4.5000e+01],\n",
       "        [-1.0800e+02, -7.6000e+01, -3.7000e+01, -1.6000e+01],\n",
       "        [-1.0900e+02, -7.0000e+01, -4.9000e+01, -2.5000e+01],\n",
       "        [-1.4200e+02, -1.1300e+02, -8.7000e+01, -1.5000e+01],\n",
       "        [-8.7000e+01, -6.5000e+01, -2.7000e+01, -3.0000e+00],\n",
       "        [-1.1300e+02, -8.3000e+01, -4.0000e+01, -7.0000e+00],\n",
       "        [-1.4400e+02, -1.0100e+02, -6.2000e+01, -2.9000e+01],\n",
       "        [-9.3000e+01, -5.8000e+01, -3.2000e+01, -7.0000e+00],\n",
       "        [-8.2000e+01, -5.7000e+01, -3.4000e+01, -7.0000e+00],\n",
       "        [-9.6000e+01, -6.5000e+01, -4.3000e+01, -2.2000e+01],\n",
       "        [-9.3000e+01, -5.3000e+01, -2.5000e+01, -1.0000e+00],\n",
       "        [-1.1800e+02, -8.3000e+01, -4.8000e+01, -1.0000e+01],\n",
       "        [-8.3000e+01, -5.8000e+01, -2.9000e+01, -6.0000e+00],\n",
       "        [-1.4900e+02, -1.0800e+02, -8.2000e+01, -3.1000e+01],\n",
       "        [-8.9000e+01, -6.3000e+01, -4.2000e+01, -1.8000e+01],\n",
       "        [-1.1600e+02, -9.1000e+01, -6.5000e+01, -3.0000e+01],\n",
       "        [-7.9000e+01, -5.1000e+01, -2.4000e+01, -2.0000e+00],\n",
       "        [-9.3000e+01, -6.9000e+01, -3.6000e+01, -1.1000e+01],\n",
       "        [-1.1100e+02, -8.3000e+01, -6.2000e+01, -3.3000e+01],\n",
       "        [-1.2700e+02, -8.5000e+01, -5.2000e+01, -2.0000e+01],\n",
       "        [-1.0900e+02, -6.4000e+01, -3.9000e+01, -3.0000e+00],\n",
       "        [-8.2000e+01, -6.0000e+01, -3.5000e+01, -7.0000e+00],\n",
       "        [-1.0400e+02, -8.2000e+01, -5.6000e+01, -3.0000e+01],\n",
       "        [-1.2700e+02, -1.0600e+02, -5.4000e+01, -2.7000e+01],\n",
       "        [-1.2400e+02, -8.6000e+01, -6.2000e+01, -3.1000e+01],\n",
       "        [-1.0700e+02, -8.4000e+01, -4.6000e+01, -2.2000e+01],\n",
       "        [-1.1000e+02, -8.8000e+01, -5.9000e+01, -1.0000e+01],\n",
       "        [-1.0600e+02, -8.4000e+01, -5.9000e+01, -2.0000e+01],\n",
       "        [-8.8000e+01, -5.8000e+01, -3.3000e+01, -1.1000e+01],\n",
       "        [-8.3000e+01, -6.1000e+01, -3.8000e+01, -1.2000e+01],\n",
       "        [-8.2000e+01, -4.6000e+01, -2.5000e+01, -2.0000e+00],\n",
       "        [-1.6600e+02, -1.2000e+02, -7.8000e+01, -5.5000e+01],\n",
       "        [-7.7000e+01, -5.3000e+01, -2.9000e+01, -2.0000e+00],\n",
       "        [-1.0300e+02, -7.5000e+01, -5.1000e+01, -2.5000e+01],\n",
       "        [-7.7000e+01, -5.6000e+01, -3.2000e+01, -6.0000e+00],\n",
       "        [-1.3100e+02, -9.2000e+01, -5.2000e+01, -2.2000e+01],\n",
       "        [-1.2800e+02, -8.6000e+01, -5.7000e+01, -1.6000e+01],\n",
       "        [-8.7000e+01, -6.4000e+01, -4.3000e+01, -2.2000e+01],\n",
       "        [-1.0300e+02, -8.1000e+01, -4.7000e+01, -2.2000e+01],\n",
       "        [-9.7000e+01, -6.4000e+01, -4.3000e+01, -1.4000e+01],\n",
       "        [-1.0200e+02, -7.1000e+01, -3.8000e+01, -1.2000e+01],\n",
       "        [-1.1900e+02, -8.9000e+01, -6.5000e+01, -2.8000e+01],\n",
       "        [-1.4900e+02, -1.2800e+02, -8.0000e+01, -3.8000e+01],\n",
       "        [-1.1400e+02, -8.3000e+01, -5.9000e+01, -2.8000e+01],\n",
       "        [-9.5000e+01, -6.1000e+01, -3.2000e+01, -5.0000e+00],\n",
       "        [-1.0700e+02, -8.1000e+01, -5.0000e+01, -1.6000e+01],\n",
       "        [-1.1500e+02, -8.7000e+01, -5.4000e+01, -9.0000e+00],\n",
       "        [-8.7000e+01, -5.9000e+01, -3.7000e+01, -3.0000e+00],\n",
       "        [-8.8000e+01, -6.4000e+01, -4.1000e+01, -1.4000e+01],\n",
       "        [-8.7000e+01, -6.2000e+01, -3.4000e+01, -5.0000e+00],\n",
       "        [-1.1100e+02, -8.6000e+01, -3.7000e+01, -1.3000e+01],\n",
       "        [-1.0400e+02, -7.9000e+01, -5.1000e+01, -1.4000e+01],\n",
       "        [-8.2000e+01, -6.0000e+01, -3.7000e+01, -1.3000e+01],\n",
       "        [-1.2800e+02, -8.7000e+01, -5.5000e+01, -1.4000e+01],\n",
       "        [-8.7000e+01, -6.2000e+01, -2.8000e+01, -7.0000e+00],\n",
       "        [-7.7000e+01, -4.8000e+01, -2.6000e+01, -3.0000e+00],\n",
       "        [-9.2000e+01, -4.9000e+01, -2.6000e+01, -2.0000e+00],\n",
       "        [-9.7000e+01, -7.2000e+01, -4.8000e+01, -1.1000e+01],\n",
       "        [-8.3000e+01, -6.2000e+01, -3.6000e+01, -1.3000e+01],\n",
       "        [-1.1000e+02, -7.1000e+01, -3.5000e+01, -1.0000e+01],\n",
       "        [-1.5200e+02, -1.3100e+02, -9.4000e+01, -2.0000e+01],\n",
       "        [-9.3000e+01, -6.7000e+01, -4.0000e+01, -1.3000e+01],\n",
       "        [-1.0100e+02, -7.5000e+01, -4.6000e+01, -1.4000e+01],\n",
       "        [-9.2000e+01, -5.6000e+01, -3.3000e+01, -9.0000e+00],\n",
       "        [-1.1300e+02, -8.2000e+01, -5.6000e+01, -2.5000e+01],\n",
       "        [-9.8000e+01, -7.1000e+01, -4.0000e+01, -1.2000e+01],\n",
       "        [-1.5100e+02, -1.2800e+02, -6.7000e+01, -3.1000e+01],\n",
       "        [-8.7000e+01, -6.0000e+01, -3.9000e+01, -1.7000e+01],\n",
       "        [-1.2400e+02, -9.5000e+01, -5.9000e+01, -3.3000e+01],\n",
       "        [-9.4000e+01, -6.3000e+01, -3.8000e+01, -1.7000e+01],\n",
       "        [-1.1000e+02, -8.5000e+01, -4.7000e+01, -2.4000e+01],\n",
       "        [-1.3900e+02, -8.9000e+01, -4.9000e+01, -2.8000e+01],\n",
       "        [-1.0700e+02, -7.3000e+01, -4.1000e+01, -1.3000e+01],\n",
       "        [-9.0000e+01, -6.2000e+01, -4.0000e+01, -5.0000e+00],\n",
       "        [-1.2700e+02, -9.1000e+01, -6.6000e+01, -3.9000e+01],\n",
       "        [-1.0700e+02, -8.2000e+01, -5.8000e+01, -2.6000e+01],\n",
       "        [-1.0100e+02, -6.9000e+01, -4.1000e+01, -1.7000e+01],\n",
       "        [-9.1000e+01, -5.9000e+01, -3.8000e+01, -3.0000e+00],\n",
       "        [-1.2500e+02, -9.4000e+01, -7.3000e+01, -2.6000e+01],\n",
       "        [-1.0800e+02, -8.7000e+01, -4.3000e+01, -1.3000e+01],\n",
       "        [-9.6000e+01, -7.3000e+01, -4.6000e+01, -1.8000e+01],\n",
       "        [-7.8000e+01, -5.2000e+01, -3.1000e+01, -6.0000e+00],\n",
       "        [-9.2000e+01, -5.4000e+01, -3.1000e+01, -5.0000e+00],\n",
       "        [-1.1900e+02, -9.3000e+01, -5.2000e+01, -2.4000e+01],\n",
       "        [-1.2600e+02, -1.0500e+02, -6.7000e+01, -2.3000e+01],\n",
       "        [-1.1100e+02, -7.8000e+01, -5.2000e+01, -2.5000e+01],\n",
       "        [-1.0200e+02, -7.9000e+01, -5.5000e+01, -2.5000e+01],\n",
       "        [-1.3000e+02, -1.0700e+02, -8.5000e+01, -5.1000e+01],\n",
       "        [-1.2500e+02, -9.9000e+01, -4.8000e+01, -2.3000e+01],\n",
       "        [-9.4000e+01, -5.7000e+01, -3.6000e+01, -1.4000e+01],\n",
       "        [-9.7000e+01, -7.2000e+01, -3.8000e+01, -1.6000e+01],\n",
       "        [-8.6000e+01, -5.1000e+01, -3.0000e+01, -9.0000e+00],\n",
       "        [-1.1200e+02, -7.7000e+01, -3.9000e+01, -1.7000e+01],\n",
       "        [-1.2300e+02, -8.2000e+01, -3.9000e+01, -1.1000e+01],\n",
       "        [-1.1800e+02, -9.5000e+01, -6.9000e+01, -7.0000e+00],\n",
       "        [-9.1000e+01, -6.8000e+01, -4.0000e+01, -1.3000e+01],\n",
       "        [-1.4000e+02, -1.0200e+02, -6.8000e+01, -4.1000e+01],\n",
       "        [-8.6000e+01, -6.2000e+01, -2.4000e+01, -3.0000e+00],\n",
       "        [-1.1100e+02, -7.2000e+01, -3.5000e+01, -1.4000e+01],\n",
       "        [-9.2000e+01, -5.0000e+01, -2.9000e+01, -3.0000e+00],\n",
       "        [-8.2000e+01, -5.1000e+01, -3.0000e+01, -1.0000e+00],\n",
       "        [-1.0000e+02, -6.8000e+01, -4.5000e+01, -1.9000e+01],\n",
       "        [-1.3200e+02, -1.1000e+02, -8.8000e+01, -1.0000e+01],\n",
       "        [-9.6000e+01, -7.1000e+01, -4.4000e+01, -1.4000e+01],\n",
       "        [-1.1400e+02, -6.4000e+01, -3.3000e+01, -1.1000e+01],\n",
       "        [-1.1000e+02, -8.4000e+01, -6.3000e+01, -2.1000e+01],\n",
       "        [-1.1700e+02, -7.7000e+01, -4.6000e+01, -1.8000e+01],\n",
       "        [-1.3000e+02, -1.0500e+02, -4.7000e+01, -2.2000e+01],\n",
       "        [-8.8000e+01, -6.5000e+01, -4.4000e+01, -1.4000e+01],\n",
       "        [-8.4000e+01, -5.5000e+01, -2.4000e+01, -1.0000e+00],\n",
       "        [-1.2200e+02, -8.0000e+01, -5.9000e+01, -2.2000e+01],\n",
       "        [-1.0400e+02, -7.4000e+01, -4.5000e+01, -2.3000e+01],\n",
       "        [-1.3700e+02, -9.0000e+01, -4.5000e+01, -2.4000e+01],\n",
       "        [-1.0400e+02, -7.8000e+01, -5.0000e+01, -2.0000e+01],\n",
       "        [-8.7000e+01, -5.2000e+01, -3.0000e+01, -6.0000e+00],\n",
       "        [-1.0000e+02, -7.2000e+01, -4.6000e+01, -2.0000e+00],\n",
       "        [-8.4000e+01, -6.1000e+01, -3.3000e+01, -8.0000e+00],\n",
       "        [-8.7000e+01, -6.3000e+01, -4.2000e+01, -2.0000e+01],\n",
       "        [-1.0000e+02, -7.3000e+01, -2.6000e+01, -5.0000e+00],\n",
       "        [-9.0000e+01, -6.9000e+01, -4.6000e+01, -4.0000e+00],\n",
       "        [-1.2700e+02, -9.7000e+01, -6.3000e+01, -2.7000e+01],\n",
       "        [-1.1000e+02, -7.8000e+01, -5.3000e+01, -2.2000e+01],\n",
       "        [-1.2400e+02, -9.9000e+01, -7.1000e+01, -2.1000e+01],\n",
       "        [-8.2000e+01, -5.9000e+01, -3.5000e+01, -1.4000e+01],\n",
       "        [-1.1300e+02, -8.9000e+01, -6.2000e+01, -1.5000e+01],\n",
       "        [-7.7000e+01, -5.6000e+01, -3.5000e+01, -6.0000e+00],\n",
       "        [-1.6900e+02, -1.1300e+02, -6.6000e+01, -3.1000e+01],\n",
       "        [-1.5200e+02, -1.1200e+02, -6.9000e+01, -1.7000e+01],\n",
       "        [-1.3100e+02, -8.4000e+01, -4.9000e+01, -2.8000e+01],\n",
       "        [-9.1000e+01, -7.0000e+01, -4.7000e+01, -2.5000e+01],\n",
       "        [-7.9000e+01, -5.7000e+01, -3.4000e+01, -1.0000e+01],\n",
       "        [-8.9000e+01, -5.9000e+01, -3.0000e+01, -8.0000e+00],\n",
       "        [-8.6000e+01, -5.7000e+01, -3.0000e+01, -9.0000e+00],\n",
       "        [-1.1400e+02, -8.2000e+01, -5.7000e+01, -1.5000e+01],\n",
       "        [-9.9000e+01, -6.4000e+01, -4.3000e+01, -1.2000e+01],\n",
       "        [-1.0000e+02, -7.8000e+01, -4.4000e+01, -1.2000e+01],\n",
       "        [-9.4000e+01, -7.2000e+01, -5.0000e+01, -1.0000e+01],\n",
       "        [-1.5400e+02, -1.2600e+02, -7.6000e+01, -2.4000e+01],\n",
       "        [-1.0900e+02, -6.3000e+01, -4.1000e+01, -1.3000e+01],\n",
       "        [-1.1500e+02, -9.3000e+01, -2.8000e+01, -2.0000e+00],\n",
       "        [-1.2000e+02, -9.8000e+01, -6.2000e+01, -1.8000e+01],\n",
       "        [-1.0700e+02, -7.4000e+01, -3.9000e+01, -1.4000e+01],\n",
       "        [-1.2200e+02, -9.2000e+01, -6.7000e+01, -2.7000e+01],\n",
       "        [-1.0200e+02, -7.7000e+01, -5.5000e+01, -2.5000e+01],\n",
       "        [-9.1000e+01, -5.4000e+01, -3.1000e+01, -6.0000e+00],\n",
       "        [-1.1200e+02, -7.6000e+01, -4.9000e+01, -2.2000e+01],\n",
       "        [-1.3400e+02, -1.0300e+02, -7.6000e+01, -5.3000e+01],\n",
       "        [-1.4900e+02, -1.2300e+02, -5.7000e+01, -2.6000e+01],\n",
       "        [-8.0000e+01, -5.7000e+01, -3.0000e+01, -1.0000e+00],\n",
       "        [-1.0300e+02, -7.8000e+01, -3.8000e+01, -1.7000e+01],\n",
       "        [-8.3000e+01, -6.1000e+01, -3.6000e+01, -6.0000e+00],\n",
       "        [-1.2500e+02, -8.8000e+01, -5.2000e+01, -2.7000e+01],\n",
       "        [-1.3600e+02, -1.0100e+02, -7.6000e+01, -3.7000e+01],\n",
       "        [-8.8000e+01, -5.9000e+01, -3.3000e+01, -1.0000e+01],\n",
       "        [-1.1300e+02, -8.6000e+01, -4.2000e+01, -2.0000e+01],\n",
       "        [-1.1600e+02, -8.0000e+01, -5.5000e+01, -3.4000e+01],\n",
       "        [-9.9000e+01, -6.8000e+01, -4.2000e+01, -1.4000e+01],\n",
       "        [-1.3300e+02, -1.0100e+02, -7.9000e+01, -2.0000e+01],\n",
       "        [-1.0600e+02, -8.5000e+01, -6.1000e+01, -3.3000e+01],\n",
       "        [-9.4000e+01, -7.1000e+01, -4.5000e+01, -6.0000e+00],\n",
       "        [-8.8000e+01, -6.4000e+01, -4.2000e+01, -2.1000e+01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39098117",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = torch.FloatTensor(L,K).uniform_(0, M*Nr)\n",
    "origins = torch.randint(0, L, (L,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e9c7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = -Nr / lambertw(-1e-3 / math.exp(1), -1).real\n",
    "beta = math.exp(1)\n",
    "impulse_resp = lambda t_: (t_>=0) * t_ / beta * torch.exp(1 - t_ / beta)\n",
    "impulse_resp_deriv = lambda t_: 1/beta * (1 - t_/beta) * torch.exp(1 - t_/beta) * (t_ >= 0)\n",
    "\n",
    "plt.plot(torch.linspace(0, Nr, 100), impulse_resp(torch.linspace(0, Nr, 100)))\n",
    "plt.plot(torch.linspace(0, Nr, 100), impulse_resp_deriv(torch.linspace(0, Nr, 100)))\n",
    "plt.legend([r\"$h(\\cdot)$\", r\"$h'(\\cdot)$\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b466eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1\n",
    "wmax = 0.1\n",
    "firing_thresh, resting_thresh = 1, 0\n",
    "min_slope = (firing_thresh - resting_thresh)/eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d46e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_segmentation = segment_firing_sequences(spike_sequences, Nr, eps)\n",
    "at_firing = torch.argwhere(spike_sequences)\n",
    "after_firing = torch.argwhere(firing_segmentation == 0)\n",
    "before_firing = torch.argwhere(firing_segmentation == 1)\n",
    "around_firing = torch.argwhere(firing_segmentation == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be980113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation matrix\n",
    "C = compute_observation_tensor(spike_sequences, delays, origins, Nr, (impulse_resp, impulse_resp_deriv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6771f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(filename, itr, levels, slopes, weights, firing_times, orange_region, blue_region):\n",
    "    fig, ax = plt.subplots(3, figsize=(20, 20))\n",
    "    \n",
    "    ax[0].set_title(f\"score (level) at iteration {itr}\")\n",
    "    ax[1].set_title(f\"score (slope) at iteration {itr}\")\n",
    "    ax[2].set_title(f\"weights at iteration {itr}\")\n",
    "\n",
    "    # at firing\n",
    "    for i in range(firing_times.size(0)):\n",
    "        ax[0].axvline(firing_times[i], color='orange')\n",
    "        ax[1].axvline(firing_times[i], color='orange')\n",
    "\n",
    "    # around firing\n",
    "    for i in range(orange_region[0].size(0)):\n",
    "        ax[0].axvspan(orange_region[0][i] - 0.5, orange_region[1][i] + 0.5, facecolor='orange', alpha=0.3)\n",
    "        ax[1].axvspan(orange_region[0][i] - 0.5, orange_region[1][i] + 0.5, facecolor='orange', alpha=0.3)\n",
    "\n",
    "    # before firing\n",
    "    for i in range(blue_region[0].size(0)):\n",
    "        ax[0].axvspan(blue_region[0][i] - 0.5, blue_region[1][i] + 0.5, facecolor='blue', alpha=0.3)\n",
    "        ax[1].axvspan(blue_region[0][i] - 0.5, blue_region[1][i] + 0.5, facecolor='blue', alpha=0.3)\n",
    "\n",
    "    ax[0].axhline(resting_thresh, linestyle=\"dashed\")\n",
    "    ax[0].axhline(firing_thresh, linestyle=\"dashed\")\n",
    "    ax[1].axhline(min_slope, linestyle=\"dashed\")\n",
    "    ax[2].axhline(wmax, linestyle=\"dashed\")\n",
    "    ax[2].axhline(-wmax, linestyle=\"dashed\")\n",
    "        \n",
    "    ax[0].plot(levels, color=\"red\")\n",
    "    ax[1].plot(slopes, color=\"red\")\n",
    "    ax[2].plot(weights, color=\"red\")\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d3195",
   "metadata": {},
   "source": [
    "# 1. Box constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "99422727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [06:59<00:00,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error weight is 0.1894119644165039\n",
      "error at firing time is 0.0\n",
      "error around firing time is 0.04388230323791504\n",
      "error before firing time is 0.0010974971950054168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save = False\n",
    "\n",
    "# init with random weights between wmin and wmax\n",
    "mw = torch.FloatTensor(L,K).uniform_(-wmax,wmax)\n",
    "my = (C @ mw.view(1, L, K, 1)).view(N, L, 2)\n",
    "\n",
    "if save:\n",
    "    orange_region = indices_to_start_end(torch.argwhere(firing_segmentation[:,42] == 2).flatten()) \n",
    "    blue_region = indices_to_start_end(torch.argwhere(firing_segmentation[:,42] == 1).flatten())  \n",
    "    firing_times = torch.argwhere(spike_sequences[:,42])\n",
    "    save_img(\"learning/box_learning_0.png\", 0, my[:,42,0], my[:,42,1], mw[42].sort()[0], firing_times, orange_region, blue_region)\n",
    "\n",
    "for itr in tqdm(range(1, 51)):\n",
    "    # priors\n",
    "    ## weights\n",
    "    mw_f, Vw_f = compute_box_prior(mw, -wmax, wmax, 1000)\n",
    "    \n",
    "    ## inputs\n",
    "    my_b = torch.zeros(N, L, 2)\n",
    "    Vy_b = 1e9 * torch.ones(N, L, 2)\n",
    "    my_b[before_firing[:,0],before_firing[:,1],0], Vy_b[before_firing[:,0],before_firing[:,1],0] = compute_box_prior(my[before_firing[:,0],before_firing[:,1],0], None, resting_thresh, 100)\n",
    "    my_b[around_firing[:,0],around_firing[:,1],1], Vy_b[around_firing[:,0],around_firing[:,1],1] = compute_box_prior(my[around_firing[:,0],around_firing[:,1],1], min_slope, None, 1000)\n",
    "    my_b[at_firing[:,0],at_firing[:,1],0], Vy_b[at_firing[:,0],at_firing[:,1],0] = compute_box_prior(my[at_firing[:,0],at_firing[:,1],0], firing_thresh, firing_thresh, 1)\n",
    "        \n",
    "    # posteriors\n",
    "    mw, _, my = compute_posterior(mw_f, Vw_f, my_b, Vy_b, C)\n",
    "    \n",
    "    if save:\n",
    "        save_img(f\"learning/box_learning_{itr}.png\", itr, my[:,42,0], my[:,42,1], mw[42].sort()[0], firing_times, orange_region, blue_region)\n",
    "\n",
    "print(f\"error weight is {(torch.abs(mw-wmax) + torch.abs(mw+wmax) - 2*wmax).sum().item()/L}\")\n",
    "print(f\"error at firing time is {(my_b[at_firing[:,0], at_firing[:,1], 0] - firing_thresh).abs().sum().item()/L}\")\n",
    "print(f\"error around firing time is {torch.maximum(min_slope - my[around_firing[:,0],around_firing[:,1],1], torch.tensor(0)).sum().item()/L}\")\n",
    "print(f\"error before firing time is {torch.maximum(my[before_firing[:,0],before_firing[:,1],0] - resting_thresh, torch.tensor(0)).sum().item()/L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16977385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 300, 20, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, L, K, Nr, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23fef3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.1, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_slope, wmax, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d5f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mw, \"weights_box.pt\")\n",
    "# torch.save(delays, \"delays.pt\")\n",
    "# torch.save(origins, \"origins.pt\")\n",
    "# torch.save(spike_sequences, \"spike_sequences.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a0f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw = torch.load(\"weights_box.pt\")\n",
    "delays = torch.load(\"delays.pt\")\n",
    "origins = torch.load(\"origins.pt\")\n",
    "spike_sequences = torch.load(\"spike_sequences.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "649cc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = compute_jitter_transition_tensor(spike_sequences, mw, delays, origins, Nr, impulse_resp_deriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb6c1b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 800, 800])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9bac51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvals(A).abs().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e165c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 6.4751e-12, 7.0725e-12, 2.3415e-11, 2.9520e-11, 3.2140e-11,\n",
       "        4.3820e-11, 6.1657e-11, 7.9993e-11, 8.8780e-11, 1.2709e-10, 1.5276e-10,\n",
       "        2.9493e-10, 4.0992e-10, 4.3540e-10, 5.0658e-10, 7.5470e-10, 8.9182e-10,\n",
       "        1.0511e-09, 1.9331e-09, 2.0371e-09, 2.0670e-09, 2.1189e-09, 2.4701e-09,\n",
       "        2.5008e-09, 2.7681e-09, 3.1287e-09, 3.2102e-09, 4.0791e-09, 4.6076e-09,\n",
       "        4.7052e-09, 5.3169e-09, 5.3978e-09, 5.7759e-09, 5.9731e-09, 6.4358e-09,\n",
       "        6.6663e-09, 7.5601e-09, 7.9009e-09, 8.7846e-09, 9.8347e-09, 1.0090e-08,\n",
       "        1.2271e-08, 1.3043e-08, 1.3185e-08, 1.4133e-08, 1.4187e-08, 1.4903e-08,\n",
       "        1.5341e-08, 1.5453e-08, 1.7468e-08, 1.8636e-08, 2.3796e-08, 2.4565e-08,\n",
       "        2.4725e-08, 2.5032e-08, 2.5632e-08, 2.7222e-08, 2.8633e-08, 3.0434e-08,\n",
       "        3.3407e-08, 3.3838e-08, 3.4508e-08, 3.6856e-08, 3.8180e-08, 4.0761e-08,\n",
       "        4.1598e-08, 4.4425e-08, 4.9934e-08, 5.0154e-08, 5.1941e-08, 5.5048e-08,\n",
       "        5.7089e-08, 5.8491e-08, 5.9389e-08, 6.1174e-08, 6.1565e-08, 6.4446e-08,\n",
       "        6.7778e-08, 6.7924e-08, 7.2130e-08, 8.4938e-08, 8.5350e-08, 1.0333e-07,\n",
       "        1.0891e-07, 1.1019e-07, 1.2298e-07, 1.3394e-07, 1.3889e-07, 1.4477e-07,\n",
       "        1.5262e-07, 1.5285e-07, 1.5398e-07, 1.5726e-07, 1.6004e-07, 1.6338e-07,\n",
       "        1.7221e-07, 1.8450e-07, 1.9883e-07, 2.0603e-07, 2.5326e-07, 2.5341e-07,\n",
       "        2.5646e-07, 2.5742e-07, 2.8241e-07, 2.9468e-07, 3.0094e-07, 3.4562e-07,\n",
       "        3.9122e-07, 3.9898e-07, 4.0352e-07, 4.2343e-07, 4.2970e-07, 4.6103e-07,\n",
       "        4.9631e-07, 4.9807e-07, 5.1530e-07, 5.5829e-07, 5.6820e-07, 6.0695e-07,\n",
       "        6.2070e-07, 7.4204e-07, 7.6692e-07, 7.8278e-07, 8.4566e-07, 8.6514e-07,\n",
       "        8.6524e-07, 9.0102e-07, 9.1349e-07, 9.8674e-07, 1.0035e-06, 1.0603e-06,\n",
       "        1.0805e-06, 1.0854e-06, 1.3270e-06, 1.3628e-06, 1.4581e-06, 1.4610e-06,\n",
       "        1.4638e-06, 1.5480e-06, 1.7014e-06, 1.7537e-06, 1.7566e-06, 1.7938e-06,\n",
       "        1.8131e-06, 1.8211e-06, 1.8655e-06, 1.8706e-06, 1.9119e-06, 1.9365e-06,\n",
       "        1.9533e-06, 2.2095e-06, 2.2483e-06, 2.5262e-06, 2.6856e-06, 2.9616e-06,\n",
       "        3.1510e-06, 3.5208e-06, 3.6326e-06, 3.6846e-06, 4.3660e-06, 4.4685e-06,\n",
       "        4.6048e-06, 4.7378e-06, 4.8123e-06, 4.8259e-06, 5.1067e-06, 5.1758e-06,\n",
       "        5.5046e-06, 5.5862e-06, 5.9977e-06, 6.1201e-06, 6.6915e-06, 6.7872e-06,\n",
       "        7.5028e-06, 8.0642e-06, 8.7506e-06, 9.0239e-06, 9.7909e-06, 9.8748e-06,\n",
       "        1.0398e-05, 1.0964e-05, 1.1508e-05, 1.2374e-05, 1.2924e-05, 1.4844e-05,\n",
       "        1.6626e-05, 1.7768e-05, 2.3715e-05, 2.4587e-05, 2.7628e-05, 2.8007e-05,\n",
       "        3.6132e-05, 3.6939e-05, 4.9439e-05, 5.3776e-05, 5.5960e-05, 7.1148e-05,\n",
       "        7.1380e-05, 1.0488e-04])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, _  = torch.linalg.eigvals(A).abs().min(dim=1)\n",
    "eigvals.sort()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e087e078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi = torch.eye((M+1)*L)\n",
    "\n",
    "for n in range(N):\n",
    "    Phi = A[n] @ Phi\n",
    "    \n",
    "torch.linalg.eigvals(Phi).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89b40e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi = torch.eye((M+1)*L)\n",
    "\n",
    "for n in range(N):\n",
    "    Phi = A[(10 + n)%N] @ Phi\n",
    "    \n",
    "torch.linalg.eigvals(Phi).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7c14e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.0000)\n",
      "1 tensor(1.0000)\n",
      "2 tensor(1.0000)\n",
      "3 tensor(1.0000)\n",
      "4 tensor(1.0000)\n",
      "5 tensor(1.0000)\n",
      "6 tensor(1.0000)\n",
      "7 tensor(1.0000)\n",
      "8 tensor(1.0000)\n",
      "9 tensor(1.0000)\n",
      "10 tensor(1.0000)\n",
      "11 tensor(1.0000)\n",
      "12 tensor(1.)\n",
      "13 tensor(1.0000)\n",
      "14 tensor(1.0000)\n",
      "15 tensor(1.0000)\n",
      "16 tensor(1.0000)\n",
      "17 tensor(1.0000)\n",
      "18 tensor(1.0000)\n",
      "19 tensor(1.0000)\n",
      "20 tensor(1.0000)\n",
      "21 tensor(1.0000)\n",
      "22 tensor(1.0000)\n",
      "23 tensor(1.0000)\n",
      "24 tensor(1.0000)\n",
      "25 tensor(1.0000)\n",
      "26 tensor(1.0000)\n",
      "27 tensor(1.)\n",
      "28 tensor(1.0000)\n",
      "29 tensor(1.0000)\n",
      "30 tensor(1.0000)\n",
      "31 tensor(1.0000)\n",
      "32 tensor(1.0000)\n",
      "33 tensor(1.0000)\n",
      "34 tensor(1.0000)\n",
      "35 tensor(1.0000)\n",
      "36 tensor(1.0000)\n",
      "37 tensor(1.0000)\n",
      "38 tensor(1.0000)\n",
      "39 tensor(1.0000)\n",
      "40 tensor(1.0000)\n",
      "41 tensor(1.0000)\n",
      "42 tensor(1.0000)\n",
      "43 tensor(1.0000)\n",
      "44 tensor(1.0000)\n",
      "45 tensor(1.0000)\n",
      "46 tensor(1.0000)\n",
      "47 tensor(1.0000)\n",
      "48 tensor(1.0000)\n",
      "49 tensor(1.0000)\n",
      "50 tensor(1.0000)\n",
      "51 tensor(1.0000)\n",
      "52 tensor(1.0000)\n",
      "53 tensor(1.0000)\n",
      "54 tensor(1.0000)\n",
      "55 tensor(1.0000)\n",
      "56 tensor(1.0000)\n",
      "57 tensor(1.0000)\n",
      "58 tensor(1.0000)\n",
      "59 tensor(1.0000)\n",
      "60 tensor(1.0000)\n",
      "61 tensor(1.0000)\n",
      "62 tensor(1.0000)\n",
      "63 tensor(1.0000)\n",
      "64 tensor(1.0000)\n",
      "65 tensor(1.0000)\n",
      "66 tensor(1.0000)\n",
      "67 tensor(1.0000)\n",
      "68 tensor(1.0000)\n",
      "69 tensor(1.0000)\n",
      "70 tensor(1.0000)\n",
      "71 tensor(1.0000)\n",
      "72 tensor(1.)\n",
      "73 tensor(1.0000)\n",
      "74 tensor(1.0000)\n",
      "75 tensor(1.0000)\n",
      "76 tensor(1.0000)\n",
      "77 tensor(1.0000)\n",
      "78 tensor(1.0000)\n",
      "79 tensor(1.0000)\n",
      "80 tensor(1.0000)\n",
      "81 tensor(1.0000)\n",
      "82 tensor(1.0000)\n",
      "83 tensor(1.)\n",
      "84 tensor(1.0000)\n",
      "85 tensor(1.0000)\n",
      "86 tensor(1.)\n",
      "87 tensor(1.0000)\n",
      "88 tensor(1.0000)\n",
      "89 tensor(1.0000)\n",
      "90 tensor(1.0000)\n",
      "91 tensor(1.0000)\n",
      "92 tensor(1.0000)\n",
      "93 tensor(1.0000)\n",
      "94 tensor(1.0000)\n",
      "95 tensor(1.0000)\n",
      "96 tensor(1.0000)\n",
      "97 tensor(1.0000)\n",
      "98 tensor(1.0000)\n",
      "99 tensor(1.0000)\n",
      "100 tensor(1.0000)\n",
      "101 tensor(1.0000)\n",
      "102 tensor(1.0000)\n",
      "103 tensor(1.0000)\n",
      "104 tensor(1.)\n",
      "105 tensor(1.0000)\n",
      "106 tensor(1.0000)\n",
      "107 tensor(1.0000)\n",
      "108 tensor(1.0000)\n",
      "109 tensor(1.0000)\n",
      "110 tensor(1.0000)\n",
      "111 tensor(1.0000)\n",
      "112 tensor(1.0000)\n",
      "113 tensor(1.0000)\n",
      "114 tensor(1.0000)\n",
      "115 tensor(1.0000)\n",
      "116 tensor(1.0000)\n",
      "117 tensor(1.)\n",
      "118 tensor(1.0000)\n",
      "119 tensor(1.0000)\n",
      "120 tensor(1.0000)\n",
      "121 tensor(1.0000)\n",
      "122 tensor(1.0000)\n",
      "123 tensor(1.0000)\n",
      "124 tensor(1.0000)\n",
      "125 tensor(1.0000)\n",
      "126 tensor(1.0000)\n",
      "127 tensor(1.0000)\n",
      "128 tensor(1.0000)\n",
      "129 tensor(1.0000)\n",
      "130 tensor(1.0000)\n",
      "131 tensor(1.)\n",
      "132 tensor(1.0000)\n",
      "133 tensor(1.0000)\n",
      "134 tensor(1.0000)\n",
      "135 tensor(1.0000)\n",
      "136 tensor(1.0000)\n",
      "137 tensor(1.0000)\n",
      "138 tensor(1.0000)\n",
      "139 tensor(1.0000)\n",
      "140 tensor(1.0000)\n",
      "141 tensor(1.0000)\n",
      "142 tensor(1.0000)\n",
      "143 tensor(1.0000)\n",
      "144 tensor(1.0000)\n",
      "145 tensor(1.0000)\n",
      "146 tensor(1.0000)\n",
      "147 tensor(1.0000)\n",
      "148 tensor(1.)\n",
      "149 tensor(1.0000)\n",
      "150 tensor(1.)\n",
      "151 tensor(1.0000)\n",
      "152 tensor(1.0000)\n",
      "153 tensor(1.0000)\n",
      "154 tensor(1.0000)\n",
      "155 tensor(1.0000)\n",
      "156 tensor(1.0000)\n",
      "157 tensor(1.0000)\n",
      "158 tensor(1.0000)\n",
      "159 tensor(1.0000)\n",
      "160 tensor(1.0000)\n",
      "161 tensor(1.0000)\n",
      "162 tensor(1.0000)\n",
      "163 tensor(1.0000)\n",
      "164 tensor(1.0000)\n",
      "165 tensor(1.0000)\n",
      "166 tensor(1.)\n",
      "167 tensor(1.0000)\n",
      "168 tensor(1.0000)\n",
      "169 tensor(1.0000)\n",
      "170 tensor(1.0000)\n",
      "171 tensor(1.0000)\n",
      "172 tensor(1.0000)\n",
      "173 tensor(1.0000)\n",
      "174 tensor(1.)\n",
      "175 tensor(1.0000)\n",
      "176 tensor(1.0000)\n",
      "177 tensor(1.0000)\n",
      "178 tensor(1.0000)\n",
      "179 tensor(1.0000)\n",
      "180 tensor(1.0000)\n",
      "181 tensor(1.0000)\n",
      "182 tensor(1.0000)\n",
      "183 tensor(1.0000)\n",
      "184 tensor(1.)\n",
      "185 tensor(1.0000)\n",
      "186 tensor(1.0000)\n",
      "187 tensor(1.0000)\n",
      "188 tensor(1.)\n",
      "189 tensor(1.0000)\n",
      "190 tensor(1.0000)\n",
      "191 tensor(1.0000)\n",
      "192 tensor(1.0000)\n",
      "193 tensor(1.0000)\n",
      "194 tensor(1.0000)\n",
      "195 tensor(1.0000)\n",
      "196 tensor(1.0000)\n",
      "197 tensor(1.0000)\n",
      "198 tensor(1.0000)\n",
      "199 tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "for n0 in range(N):\n",
    "    Phi = torch.eye((M+1)*L)\n",
    "    for n in range(N):\n",
    "        Phi = A[(n0 + n)%N] @ Phi\n",
    "    print(n0, torch.linalg.eigvals(Phi).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4494e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5d73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bfc1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = torch.linalg.eigvals(Phi).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea94e7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.5813e-03,  5.3277e-05,  9.5901e-09,  ...,  3.2279e-03,\n",
       "          -4.3388e-06, -9.8587e-10],\n",
       "         [ 5.3277e-05,  2.0275e-06,  3.7194e-10,  ...,  1.0360e-04,\n",
       "          -1.4617e-07, -3.3362e-11],\n",
       "         [ 9.5901e-09,  3.7194e-10,  6.8608e-14,  ...,  1.8768e-08,\n",
       "          -2.6502e-11, -6.0477e-15],\n",
       "         ...,\n",
       "         [ 3.2279e-03,  1.0360e-04,  1.8768e-08,  ...,  7.0613e-03,\n",
       "          -8.6383e-06, -1.9659e-09],\n",
       "         [-4.3388e-06, -1.4617e-07, -2.6502e-11,  ..., -8.6383e-06,\n",
       "           1.3944e-08,  3.1863e-12],\n",
       "         [-9.8587e-10, -3.3362e-11, -6.0477e-15,  ..., -1.9659e-09,\n",
       "           3.1863e-12,  7.2851e-16]]),\n",
       " tensor([[0.0037, 0.0037, 0.0038,  ..., 0.0037, 0.0037, 0.0037],\n",
       "         [0.0037, 0.0039, 0.0038,  ..., 0.0037, 0.0037, 0.0038],\n",
       "         [0.0038, 0.0038, 0.0204,  ..., 0.0037, 0.0036, 0.0036],\n",
       "         ...,\n",
       "         [0.0037, 0.0037, 0.0037,  ..., 0.0037, 0.0037, 0.0036],\n",
       "         [0.0037, 0.0037, 0.0036,  ..., 0.0037, 0.0040, 0.0037],\n",
       "         [0.0037, 0.0038, 0.0036,  ..., 0.0036, 0.0037, 0.0050]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi.T@Phi, Phi@Phi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e49b7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 4.4649e-03, 4.4649e-03, 4.4493e-03, 4.4493e-03, 4.3859e-03,\n",
       "        4.3859e-03, 4.2346e-03, 4.2346e-03, 4.0809e-03, 4.0809e-03, 3.9513e-03,\n",
       "        3.9513e-03, 3.8223e-03, 3.8223e-03, 3.7932e-03, 3.7932e-03, 3.6084e-03,\n",
       "        3.6084e-03, 3.5817e-03, 3.5817e-03, 3.4467e-03, 3.4467e-03, 3.3708e-03,\n",
       "        3.3708e-03, 3.2936e-03, 3.2936e-03, 3.2692e-03, 3.0999e-03, 3.0999e-03,\n",
       "        3.0942e-03, 3.0942e-03, 3.0881e-03, 3.0881e-03, 3.0880e-03, 3.0828e-03,\n",
       "        3.0828e-03, 3.0535e-03, 3.0535e-03, 2.9406e-03, 2.9406e-03, 2.7559e-03,\n",
       "        2.7559e-03, 2.7402e-03, 2.7402e-03, 2.6457e-03, 2.6457e-03, 2.5926e-03,\n",
       "        2.5926e-03, 2.5696e-03, 2.5696e-03, 2.5642e-03, 2.5642e-03, 2.5396e-03,\n",
       "        2.5396e-03, 2.5317e-03, 2.5317e-03, 2.4482e-03, 2.4482e-03, 2.4123e-03,\n",
       "        2.4123e-03, 2.4042e-03, 2.1760e-03, 2.1760e-03, 2.1750e-03, 2.1750e-03,\n",
       "        2.1172e-03, 2.1172e-03, 2.0428e-03, 2.0428e-03, 2.0333e-03, 2.0333e-03,\n",
       "        1.9890e-03, 1.9890e-03, 1.9637e-03, 1.9450e-03, 1.9450e-03, 1.9053e-03,\n",
       "        1.8626e-03, 1.8626e-03, 1.8086e-03, 1.8086e-03, 1.7127e-03, 1.7127e-03,\n",
       "        1.7091e-03, 1.7091e-03, 1.7044e-03, 1.7044e-03, 1.6724e-03, 1.6610e-03,\n",
       "        1.6610e-03, 1.6421e-03, 1.6421e-03, 1.5225e-03, 1.5225e-03, 1.5102e-03,\n",
       "        1.5102e-03, 1.4631e-03, 1.4631e-03, 1.4350e-03, 1.4350e-03, 1.4342e-03,\n",
       "        1.4342e-03, 1.3973e-03, 1.3973e-03, 1.3826e-03, 1.3826e-03, 1.3520e-03,\n",
       "        1.3520e-03, 1.3495e-03, 1.3495e-03, 1.2606e-03, 1.2606e-03, 1.2299e-03,\n",
       "        1.2299e-03, 1.2256e-03, 1.2256e-03, 1.2228e-03, 1.2228e-03, 1.1608e-03,\n",
       "        1.1608e-03, 1.1397e-03, 1.1397e-03, 1.1139e-03, 1.1139e-03, 1.0674e-03,\n",
       "        1.0645e-03, 1.0645e-03, 1.0177e-03, 1.0177e-03, 9.9661e-04, 9.9661e-04,\n",
       "        9.8177e-04, 9.8177e-04, 9.7945e-04, 9.7945e-04, 9.5724e-04, 9.5724e-04,\n",
       "        9.2616e-04, 8.8794e-04, 8.8794e-04, 8.8148e-04, 8.8148e-04, 8.7437e-04,\n",
       "        8.7437e-04, 8.4963e-04, 8.4963e-04, 8.1206e-04, 8.1206e-04, 7.9690e-04,\n",
       "        7.9690e-04, 7.8690e-04, 7.7159e-04, 7.7159e-04, 7.5678e-04, 7.5678e-04,\n",
       "        6.9252e-04, 6.9252e-04, 6.8808e-04, 6.8808e-04, 6.4639e-04, 6.4639e-04,\n",
       "        6.4005e-04, 6.4005e-04, 6.3454e-04, 6.3454e-04, 6.2866e-04, 6.2866e-04,\n",
       "        6.1803e-04, 6.1803e-04, 5.8738e-04, 5.8738e-04, 5.8636e-04, 5.8636e-04,\n",
       "        5.6938e-04, 5.6938e-04, 5.5646e-04, 5.5646e-04, 5.4746e-04, 5.4746e-04,\n",
       "        5.1099e-04, 5.1099e-04, 5.0423e-04, 5.0423e-04, 4.9597e-04, 4.9597e-04,\n",
       "        4.7290e-04, 4.7290e-04, 4.5108e-04, 4.5108e-04, 4.4691e-04, 4.4691e-04,\n",
       "        4.1550e-04, 4.1550e-04, 4.0076e-04, 4.0076e-04, 4.0055e-04, 4.0055e-04,\n",
       "        3.9595e-04, 3.9595e-04, 3.9497e-04, 3.9497e-04, 3.8956e-04, 3.8956e-04,\n",
       "        3.7872e-04, 3.6981e-04, 3.6981e-04, 3.3865e-04, 3.1526e-04, 3.1526e-04,\n",
       "        3.0485e-04, 3.0485e-04, 3.0020e-04, 3.0020e-04, 2.9778e-04, 2.9778e-04,\n",
       "        2.9458e-04, 2.9458e-04, 2.8322e-04, 2.8322e-04, 2.8086e-04, 2.8086e-04,\n",
       "        2.7989e-04, 2.7989e-04, 2.7105e-04, 2.6726e-04, 2.6726e-04, 2.5522e-04,\n",
       "        2.5522e-04, 2.4246e-04, 2.4246e-04, 2.3962e-04, 2.3962e-04, 2.3177e-04,\n",
       "        2.0670e-04, 2.0670e-04, 2.0601e-04, 2.0500e-04, 2.0500e-04, 2.0371e-04,\n",
       "        2.0371e-04, 1.8410e-04, 1.8410e-04, 1.7877e-04, 1.7877e-04, 1.7653e-04,\n",
       "        1.7653e-04, 1.6301e-04, 1.6301e-04, 1.5116e-04, 1.5116e-04, 1.4829e-04,\n",
       "        1.3562e-04, 1.3562e-04, 1.3383e-04, 1.3383e-04, 1.3183e-04, 1.3183e-04,\n",
       "        1.2668e-04, 1.2668e-04, 1.1824e-04, 1.1460e-04, 1.1460e-04, 1.1242e-04,\n",
       "        1.1242e-04, 1.1191e-04, 1.1191e-04, 1.0225e-04, 1.0225e-04, 1.0118e-04,\n",
       "        1.0118e-04, 8.8400e-05, 8.2704e-05, 8.2704e-05, 8.1308e-05, 8.1308e-05,\n",
       "        7.8078e-05, 7.8078e-05, 7.7318e-05, 7.7318e-05, 6.6460e-05, 6.6460e-05,\n",
       "        6.0035e-05, 6.0035e-05, 5.9772e-05, 5.9772e-05, 5.5849e-05, 5.3217e-05,\n",
       "        5.3217e-05, 5.0700e-05, 5.0700e-05, 4.4211e-05, 4.4211e-05, 4.4037e-05,\n",
       "        4.4037e-05, 4.2917e-05, 4.2917e-05, 3.8641e-05, 3.7144e-05, 3.7144e-05,\n",
       "        3.6758e-05, 3.6758e-05, 3.4603e-05, 3.4603e-05, 3.3752e-05, 3.3752e-05,\n",
       "        3.2996e-05, 3.2996e-05, 3.0879e-05, 3.0879e-05, 2.7529e-05, 2.7529e-05,\n",
       "        2.0966e-05, 2.0966e-05, 2.0469e-05, 1.9357e-05, 1.9357e-05, 1.8285e-05,\n",
       "        1.8285e-05, 1.7395e-05, 1.6488e-05, 1.6488e-05, 1.5095e-05, 1.5095e-05,\n",
       "        1.3474e-05, 1.2480e-05, 1.2480e-05, 1.1037e-05, 1.1037e-05, 1.0884e-05,\n",
       "        1.0884e-05, 9.4134e-06, 9.4134e-06, 7.0078e-06, 7.0078e-06, 6.6161e-06,\n",
       "        6.6161e-06, 6.0592e-06, 6.0592e-06, 5.9698e-06, 5.9698e-06, 5.9671e-06,\n",
       "        5.9671e-06, 5.4171e-06, 5.4171e-06, 3.8949e-06, 3.8949e-06, 3.8752e-06,\n",
       "        3.6772e-06, 3.6772e-06, 3.6665e-06, 3.6665e-06, 2.7987e-06, 2.7987e-06,\n",
       "        2.6465e-06, 1.7875e-06, 1.7875e-06, 1.7351e-06, 1.3732e-06, 1.3732e-06,\n",
       "        1.3374e-06, 1.1050e-06, 1.0393e-06, 9.7053e-07, 9.7053e-07, 7.6703e-07,\n",
       "        7.6703e-07, 5.3714e-07, 5.3714e-07, 4.9271e-07, 4.5105e-07, 4.5105e-07,\n",
       "        4.3641e-07, 2.8806e-07, 2.5336e-07, 2.5336e-07, 2.1527e-07, 1.3371e-07,\n",
       "        1.3331e-07, 1.0998e-07, 1.0427e-07, 1.0427e-07, 8.5465e-08, 8.5465e-08,\n",
       "        7.2526e-08, 7.2526e-08, 5.8897e-08, 5.8897e-08, 5.0816e-08, 4.7331e-08,\n",
       "        4.5902e-08, 4.5902e-08, 3.7877e-08, 3.6505e-08, 3.6505e-08, 3.2628e-08,\n",
       "        3.1109e-08, 3.1109e-08, 2.7226e-08, 2.7226e-08, 2.5728e-08, 2.5728e-08,\n",
       "        2.5315e-08, 2.5315e-08, 2.4628e-08, 2.4628e-08, 2.3814e-08, 2.2028e-08,\n",
       "        2.2028e-08, 1.7479e-08, 1.7479e-08, 1.5102e-08, 1.5102e-08, 1.2728e-08,\n",
       "        1.1167e-08, 1.1000e-08, 1.1000e-08, 1.0928e-08, 1.0928e-08, 9.9938e-09,\n",
       "        9.9938e-09, 9.9648e-09, 9.9367e-09, 9.9367e-09, 9.0492e-09, 9.0492e-09,\n",
       "        8.5347e-09, 8.5347e-09, 8.3756e-09, 8.3756e-09, 7.4380e-09, 7.4380e-09,\n",
       "        6.7348e-09, 6.5614e-09, 6.5614e-09, 5.9389e-09, 5.9389e-09, 5.6783e-09,\n",
       "        5.4112e-09, 5.4112e-09, 5.3889e-09, 5.3889e-09, 4.9605e-09, 4.9605e-09,\n",
       "        4.5972e-09, 4.5972e-09, 4.3595e-09, 4.3595e-09, 3.8859e-09, 3.8859e-09,\n",
       "        3.6363e-09, 3.6363e-09, 3.3494e-09, 3.3494e-09, 3.1572e-09, 3.1572e-09,\n",
       "        2.7870e-09, 2.7870e-09, 2.7790e-09, 2.6452e-09, 2.6452e-09, 2.3537e-09,\n",
       "        2.3537e-09, 2.1844e-09, 2.1844e-09, 2.1453e-09, 2.1453e-09, 2.0052e-09,\n",
       "        2.0052e-09, 1.7906e-09, 1.7906e-09, 1.6780e-09, 1.5854e-09, 1.5854e-09,\n",
       "        1.5499e-09, 1.5499e-09, 1.5274e-09, 1.5274e-09, 1.4595e-09, 1.4595e-09,\n",
       "        1.1844e-09, 1.1844e-09, 1.1061e-09, 1.1061e-09, 1.1054e-09, 1.1054e-09,\n",
       "        1.0625e-09, 1.0625e-09, 1.0500e-09, 1.0500e-09, 9.9274e-10, 9.9274e-10,\n",
       "        9.6696e-10, 9.6696e-10, 9.5671e-10, 9.5671e-10, 9.3302e-10, 9.3302e-10,\n",
       "        8.4408e-10, 8.3143e-10, 8.3143e-10, 7.9508e-10, 7.9508e-10, 7.6982e-10,\n",
       "        7.2114e-10, 7.2114e-10, 7.0756e-10, 7.0756e-10, 7.0275e-10, 7.0275e-10,\n",
       "        6.3526e-10, 5.8181e-10, 5.8181e-10, 5.7886e-10, 5.7886e-10, 5.4279e-10,\n",
       "        5.4279e-10, 4.9534e-10, 4.9534e-10, 4.8972e-10, 4.8972e-10, 4.8642e-10,\n",
       "        4.8642e-10, 4.7107e-10, 4.7107e-10, 4.3947e-10, 4.3947e-10, 4.3512e-10,\n",
       "        4.3512e-10, 4.2642e-10, 4.1749e-10, 4.1749e-10, 3.8538e-10, 3.8538e-10,\n",
       "        3.6406e-10, 3.6406e-10, 3.5838e-10, 3.5838e-10, 3.3578e-10, 3.3578e-10,\n",
       "        3.2271e-10, 3.0659e-10, 3.0659e-10, 2.9589e-10, 2.9589e-10, 2.9095e-10,\n",
       "        2.9095e-10, 2.8690e-10, 2.8690e-10, 2.8250e-10, 2.8250e-10, 2.7416e-10,\n",
       "        2.7416e-10, 2.7330e-10, 2.7330e-10, 2.6537e-10, 2.6537e-10, 2.6182e-10,\n",
       "        2.6182e-10, 2.5104e-10, 2.5104e-10, 2.2728e-10, 2.1116e-10, 2.1116e-10,\n",
       "        1.9844e-10, 1.9844e-10, 1.8762e-10, 1.8762e-10, 1.8077e-10, 1.8077e-10,\n",
       "        1.7897e-10, 1.7897e-10, 1.7799e-10, 1.7799e-10, 1.6355e-10, 1.6355e-10,\n",
       "        1.6306e-10, 1.6306e-10, 1.5733e-10, 1.5733e-10, 1.5509e-10, 1.5509e-10,\n",
       "        1.5062e-10, 1.5062e-10, 1.4889e-10, 1.4208e-10, 1.4208e-10, 1.2091e-10,\n",
       "        1.2091e-10, 1.1011e-10, 1.1011e-10, 1.0931e-10, 1.0931e-10, 1.0435e-10,\n",
       "        1.0333e-10, 1.0333e-10, 1.0013e-10, 1.0013e-10, 9.7714e-11, 9.7714e-11,\n",
       "        9.6844e-11, 9.6844e-11, 8.8701e-11, 8.8701e-11, 8.2411e-11, 8.2411e-11,\n",
       "        8.1305e-11, 8.1305e-11, 7.9889e-11, 7.6298e-11, 6.6599e-11, 6.6599e-11,\n",
       "        6.5314e-11, 6.5314e-11, 6.3325e-11, 6.3325e-11, 6.1363e-11, 6.1363e-11,\n",
       "        6.1123e-11, 6.1123e-11, 5.6120e-11, 5.6120e-11, 5.1681e-11, 5.1681e-11,\n",
       "        4.6982e-11, 4.6982e-11, 4.6753e-11, 4.6753e-11, 3.9145e-11, 3.9145e-11,\n",
       "        3.6851e-11, 3.6851e-11, 3.6469e-11, 3.6469e-11, 3.5023e-11, 3.5023e-11,\n",
       "        2.7117e-11, 2.7117e-11, 2.5710e-11, 2.5710e-11, 2.5507e-11, 2.5259e-11,\n",
       "        2.1756e-11, 2.1756e-11, 2.0745e-11, 2.0745e-11, 2.0554e-11, 2.0554e-11,\n",
       "        1.8032e-11, 1.8032e-11, 1.5639e-11, 1.5639e-11, 1.4753e-11, 1.4753e-11,\n",
       "        1.2493e-11, 1.1599e-11, 1.1599e-11, 1.0719e-11, 1.0719e-11, 8.7746e-12,\n",
       "        8.7746e-12, 8.4719e-12, 8.4719e-12, 7.1390e-12, 7.0151e-12, 7.0151e-12,\n",
       "        6.6510e-12, 6.6510e-12, 6.4741e-12, 5.7690e-12, 5.7690e-12, 5.7184e-12,\n",
       "        5.7184e-12, 5.6669e-12, 5.6669e-12, 5.4370e-12, 5.2154e-12, 5.2154e-12,\n",
       "        4.8941e-12, 4.0932e-12, 4.0932e-12, 3.4368e-12, 3.4368e-12, 3.0037e-12,\n",
       "        2.9957e-12, 2.9957e-12, 2.8279e-12, 2.8279e-12, 2.7058e-12, 2.7058e-12,\n",
       "        2.4770e-12, 2.4770e-12, 2.2651e-12, 2.1030e-12, 2.1030e-12, 2.0045e-12,\n",
       "        2.0045e-12, 1.7936e-12, 1.4628e-12, 1.4628e-12, 1.4144e-12, 1.4144e-12,\n",
       "        1.2762e-12, 1.2762e-12, 1.2306e-12, 1.2306e-12, 1.1413e-12, 9.5810e-13,\n",
       "        9.5810e-13, 9.5391e-13, 9.5215e-13, 9.5215e-13, 8.8573e-13, 8.8573e-13,\n",
       "        6.6815e-13, 6.6815e-13, 5.9111e-13, 5.9111e-13, 4.4736e-13, 4.0606e-13,\n",
       "        4.0606e-13, 3.1145e-13, 3.1145e-13, 3.0152e-13, 3.0152e-13, 2.8379e-13,\n",
       "        2.8379e-13, 2.3690e-13, 2.3690e-13, 1.8700e-13, 1.8700e-13, 1.5951e-13,\n",
       "        1.5951e-13, 1.5588e-13, 1.5588e-13, 1.1255e-13, 9.9031e-14, 9.9031e-14,\n",
       "        9.0821e-14, 9.0821e-14, 6.4751e-14, 6.4751e-14, 6.3636e-14, 6.2647e-14,\n",
       "        6.2647e-14, 3.9096e-14, 3.7647e-14, 3.7647e-14, 3.1068e-14, 3.1068e-14,\n",
       "        2.9312e-14, 2.3696e-14, 2.3696e-14, 1.8054e-14, 1.4273e-14, 1.3960e-14,\n",
       "        1.3960e-14, 1.3109e-14, 1.3109e-14, 7.3733e-15, 7.3733e-15, 5.4445e-15,\n",
       "        5.4445e-15, 4.7724e-15, 4.7724e-15, 4.3340e-15, 3.5649e-15, 3.5649e-15,\n",
       "        2.2996e-15, 2.2444e-15, 2.2444e-15, 2.2255e-15, 2.2255e-15, 1.7840e-15,\n",
       "        1.7840e-15, 1.3617e-15, 1.3617e-15, 1.0347e-15, 1.0347e-15, 5.3915e-16,\n",
       "        3.6764e-16, 3.6764e-16, 3.6702e-16, 3.6702e-16, 2.9242e-16, 2.7385e-16,\n",
       "        2.3376e-16, 2.3376e-16, 1.2486e-16, 8.2283e-17, 8.2283e-17, 5.3024e-17,\n",
       "        5.3024e-17, 4.9726e-17, 1.3509e-17, 3.8010e-18, 3.2475e-18, 1.8679e-18,\n",
       "        4.4575e-19, 1.9355e-19])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals.sort(descending=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a500da",
   "metadata": {},
   "source": [
    "# 2. M-level constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d009e87d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (200) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p1/wl8__y5x6jgfhz_d47k5gq9m0000gn/T/ipykernel_8850/702341276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwmin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mmw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# add frames to gif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (200) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# random init of the prior messages\n",
    "M = 7\n",
    "mws = torch.FloatTensor(L,M-1,K).normal_((wmin + wmax)/(M-1), (wmax - wmin)/(M-1) * 1e-2)\n",
    "mw = mws.sum(dim=1)\n",
    "my = (C @ mw.view(L, 1, K, 1)).view(L, N, 2)\n",
    "\n",
    "# add frames to gif\n",
    "l = 42\n",
    "frames = []\n",
    "frame = add_frame(0, mw[l], my[l], theta, eta, dymin, wmin, wmax, mask_at_firing[l], mask_around_firing[l], mask_refractory_period[l])\n",
    "frames.append(frame)\n",
    "\n",
    "for itr in tqdm(range(1, 101)):\n",
    "    # priors\n",
    "    ## weights\n",
    "    mws_f, Vws_f = compute_m_ary_prior(mws, None, wmin, wmax, M, \"am\")\n",
    "    mw_f, Vw_f = mws_f.sum(dim=1), Vws_f.sum(dim=1)\n",
    "\n",
    "    ## action potentials\n",
    "    my_b = torch.zeros(L,N, 2)\n",
    "    Vy_b = 1e9 * torch.ones(L,N, 2)  \n",
    "    my_b[...,0][mask_before_firing], Vy_b[...,0][mask_before_firing] = compute_box_prior(my[...,0][mask_before_firing], None, eta, 100)\n",
    "    my_b[...,1][mask_around_firing], Vy_b[...,1][mask_around_firing] = compute_box_prior(my[...,1][mask_around_firing], dymin, None, 200)\n",
    "    my_b[...,0][mask_at_firing], Vy_b[...,0][mask_at_firing] = compute_box_prior(my[...,0][mask_at_firing], theta, theta, 200)\n",
    "\n",
    "    # posteriors\n",
    "    mw, Vw, my = compute_posterior(mw_f, Vw_f, my_b, Vy_b, C)\n",
    "    xiw = Vw_f.pow(-1) * (mw_f - mw) # (IV.9) in Loeliger2016\n",
    "    mws = mws_f - Vws_f * xiw.unsqueeze(1) # (IV.9) in Loeliger2016\n",
    "    \n",
    "    frame = add_frame(itr, mw[l], my[l], theta, eta, dymin, wmin, wmax, mask_at_firing[l], mask_around_firing[l], mask_refractory_period[l])\n",
    "    frames.append(frame)\n",
    "    \n",
    "print(f\"error at firing time is {(my[...,0][mask_at_firing] - theta).pow(2).sum().item()/L}\")\n",
    "print(f\"error around firing time is {torch.maximum(dymin - my[...,1][mask_around_firing], torch.tensor(0)).sum().item()/L}\")\n",
    "print(f\"error before firing time is {torch.maximum(my[...,0][mask_before_firing] - eta, torch.tensor(0)).sum().item()/L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b45b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if frames:\n",
    "    gif.save(frames, \"7_ary_am.gif\", duration=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a784b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init of the prior messages\n",
    "M = 7\n",
    "mws = torch.FloatTensor(L,M-1,K).normal_((wmin + wmax)/(M-1), (wmax - wmin)/(M-1) * 1e-2)\n",
    "Vws = torch.FloatTensor(L,M-1,K).normal_((wmax - wmin)/(M-1) * 1e-1, (wmax - wmin)/(M-1) * 1e-3)\n",
    "mw = mws.sum(dim=1)\n",
    "my = (C @ mw.view(L, 1, K, 1)).view(L, N, 2)\n",
    "\n",
    "# add frames to gif\n",
    "l = 42\n",
    "frames = []\n",
    "frame = add_frame(0, mw[l], my[l], theta, eta, dymin, wmin, wmax, mask_at_firing[l], mask_around_firing[l], mask_refractory_period[l])\n",
    "frames.append(frame)\n",
    "\n",
    "for itr in tqdm(range(1, 301)):\n",
    "    # priors\n",
    "    ## weights\n",
    "    mws_f, Vws_f = compute_m_ary_prior(mws, Vws, wmin, wmax, M, \"em\")\n",
    "    mw_f, Vw_f = mws_f.sum(dim=1), Vws_f.sum(dim=1)\n",
    "        \n",
    "    ## action potentials\n",
    "    my_b = torch.zeros(L,N, 2)\n",
    "    Vy_b = 1e9 * torch.ones(L,N, 2)  \n",
    "    my_b[...,0][mask_before_firing], Vy_b[...,0][mask_before_firing] = compute_box_prior(my[...,0][mask_before_firing], None, eta, 100)\n",
    "    my_b[...,1][mask_around_firing], Vy_b[...,1][mask_around_firing] = compute_box_prior(my[...,1][mask_around_firing], dymin, None, 200)\n",
    "    my_b[...,0][mask_at_firing], Vy_b[...,0][mask_at_firing] = compute_box_prior(my[...,0][mask_at_firing], theta, theta, 200)\n",
    "        \n",
    "    # posteriors\n",
    "    mw, Vw, my = compute_posterior(mw_f, Vw_f, my_b, Vy_b, C)\n",
    "\n",
    "    xiw = Vw_f.pow(-1) * (mw_f - mw) # (IV.9) in Loeliger2016\n",
    "    Ww = Vw_f.pow(-2) * (Vw_f - Vw) # (IV.13) in Loeliger2016\n",
    "    \n",
    "    mws = mws_f - Vws_f * xiw.unsqueeze(1) # (IV.9) in Loeliger2016\n",
    "    Vws = Vws_f - Vws_f.pow(2) * Ww.unsqueeze(1) # (IV.13) in Loeliger2016\n",
    "    \n",
    "    # add frames to gif\n",
    "    frame = add_frame(itr, mw[l], my[l], theta, eta, dymin, wmin, wmax, mask_at_firing[l], mask_around_firing[l], mask_refractory_period[l])\n",
    "    frames.append(frame)\n",
    "    \n",
    "print(f\"error at firing time is {(my[...,0][mask_at_firing] - theta).abs().sum().item()/L}\")\n",
    "print(f\"error around firing time is {torch.maximum(dymin - my[...,1][mask_around_firing], torch.tensor(0)).sum().item()/L}\")\n",
    "print(f\"error before firing time is {torch.maximum(my[...,0][mask_before_firing] - eta, torch.tensor(0)).sum().item()/L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33094c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if frames:\n",
    "    gif.save(frames, \"7_ary_em.gif\", duration=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f60956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
